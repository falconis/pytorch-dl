{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Neural Network",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1B6RS5Ama_zS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting up the Dataset"
      ]
    },
    {
      "metadata": {
        "id": "x4I4QHLfkYcu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4b0WCFxnlXbk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_PATH = Path('data')\n",
        "PATH = DATA_PATH / 'mnist'\n",
        "URL = \"http://deeplearning.net/data/mnist/\"\n",
        "FILENAME = \"mnist.pkl.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aEXfiNFInLFI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B0Jh-prwq0Uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import gzip\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rO2IRdd1rcW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebdecf61-42d2-4ccb-a744-77d348bf850b"
      },
      "cell_type": "code",
      "source": [
        "n, c = x_train.shape\n",
        "print(x_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2rOZyMmsrnSF",
        "colab_type": "code",
        "outputId": "c7004b58-9958-44f8-d8f0-cef328bebe5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape((28,28)), cmap='gray')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbc7e26ed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8H/LFmKD6IYI7AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8Bl1lIGYuEde",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "import torch\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4TYwxLx1DKzf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple Network Using Pytorch"
      ]
    },
    {
      "metadata": {
        "id": "kpXZ-4Ncvg6U",
        "colab_type": "code",
        "outputId": "998e915b-a2b6-4a5c-917e-48db228afcce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "biases = torch.zeros(10, requires_grad=True) \n",
        "print(weights)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0228, -0.0716, -0.0567,  ...,  0.0007, -0.0138, -0.0158],\n",
            "        [-0.0067,  0.0537, -0.0146,  ...,  0.0435, -0.0686,  0.0020],\n",
            "        [-0.0291,  0.0312,  0.0348,  ..., -0.0563, -0.0547, -0.0450],\n",
            "        ...,\n",
            "        [-0.0680,  0.0439,  0.0217,  ...,  0.0105, -0.0478,  0.0406],\n",
            "        [-0.0155, -0.0254,  0.0173,  ..., -0.0976, -0.0013, -0.0329],\n",
            "        [-0.0850, -0.0432,  0.0250,  ..., -0.0221, -0.0233, -0.0036]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NSNaYSvvE920",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Utility Functions\n"
      ]
    },
    {
      "metadata": {
        "id": "cYJ43tdNDhjw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(x):\n",
        "  return log_softmax(x @ weights + biases)\n",
        "\n",
        "def nll(input, target):\n",
        "  return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll\n",
        "\n",
        "def accuracy(output, y):\n",
        "  guesses = torch.argmax(output, dim=1)\n",
        "  return (guesses == y).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gferhkV-OnH",
        "colab_type": "code",
        "outputId": "2b9bd503-f519-46f5-8328-0ae8c4235a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "bs = 64 #batch size\n",
        "xb = x_train[:bs]\n",
        "yb = y_train[:bs]\n",
        "preds = model(xb)\n",
        "loss = loss_func(preds, yb)\n",
        "print(loss, weights.grad)\n",
        "loss.backward()\n",
        "\n",
        "print(loss, weights.grad)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3477, grad_fn=<NegBackward>) None\n",
            "tensor(2.3477, grad_fn=<NegBackward>) tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JiSrPcGdT04O",
        "colab_type": "code",
        "outputId": "1c5cce40-cb5c-46df-f866-1ec38f6c7f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(accuracy(preds, yb))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0938)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IUh1LQr2GT4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now run a training loop. For each iteration, we will:\n",
        "\n",
        "* select a mini-batch of data (of size bs)\n",
        "* use the model to make predictions\n",
        "* calculate the loss\n",
        "* loss.backward() updates the gradients of the model, in this case, weights and bias."
      ]
    },
    {
      "metadata": {
        "id": "4n4lK26oDQuW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "lr = 0.9\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//(bs + 1)):\n",
        "#     set_trace()\n",
        "    start = i * bs\n",
        "    end = start + bs\n",
        "    xb = x_train[start:end]\n",
        "    yb = y_train[start:end]\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "    with torch.no_grad(): # We do this within the torch.no_grad() context manager, because we do not want these actions to be recorded for our next calculation of the gradient. \n",
        "      weights -= weights.grad * lr\n",
        "      biases -= biases.grad * lr\n",
        "      weights.grad.zero_()\n",
        "      biases.grad.zero_()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlOAJsncT8aI",
        "colab_type": "code",
        "outputId": "0f0c107d-4f5b-4a1c-f890-38371eed4263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2222, grad_fn=<NegBackward>) tensor(0.9219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NxB6lnSXU2bG",
        "colab_type": "code",
        "outputId": "87c9c5dd-b350-4ba9-a09d-6018bba85028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(biases)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.8556,  0.5527,  0.3834, -0.4120,  0.0105,  2.6124, -0.3716,  1.1791,\n",
            "        -2.6264, -0.4725], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ePV4u2PVX58p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1st Refactor using torch.nn.functional\n",
        "\n",
        "* torch.nn.functional contains all the functions of the torch.nn library, wheras the other parts have classes.\n",
        "* This part contains useful functions like the loss functions"
      ]
    },
    {
      "metadata": {
        "id": "V3tQKdn2X_tm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy # Remember, we just refactored our log_softmax and nll using just one line. It combines softmax and nll\n",
        "\n",
        "def model(xb):\n",
        "  return (xb @ weights + biases) # We aren't also calling log_softmax in our model function, thus making our code more modular"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OV4rM5COYtRH",
        "colab_type": "code",
        "outputId": "6c412623-999b-48c5-b90b-38099c96bc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2222, grad_fn=<NllLossBackward>) tensor(0.9219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aN9KBFkrag1Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2nd Refactor using torch.nn.Module\n",
        "* It is used to create classes for our models\n",
        "* These classes keep track of parameters and other important stuff"
      ]
    },
    {
      "metadata": {
        "id": "ebqumVpocIN-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class My_MNIST_Solver(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "    self.biases = nn.Parameter(torch.zeros(10))\n",
        "    \n",
        "  def forward(self, xb):\n",
        "    return xb @ self.weights + self.biases \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZeJUF3ntdAqX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = My_MNIST_Solver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFClL1mgd__c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can use model.parameters and model.zero grad to further refactorize our training loop"
      ]
    },
    {
      "metadata": {
        "id": "R5BVH7oMeJI-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fit(epochs=2, lr=0.5):\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n -1) // (bs + 1)):\n",
        "      start = i * bs\n",
        "      end = start + bs\n",
        "      xb = x_train[start:end]\n",
        "      yb = y_train[start:end]\n",
        "      preds = model(xb)\n",
        "      loss = loss_func(preds, yb)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * lr\n",
        "        model.zero_grad() # Reset grads to zero for all parameter of the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cADMSDgJY0YY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fmygQf2gY1aF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abc2f659-7036-47c9-8902-25445097b9b0"
      },
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2798, grad_fn=<NllLossBackward>) tensor(0.9219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A1_ixjxOZon9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3rd Refactor using nn.Linear\n",
        "* nn.Linear is a predefined layer in pytorch. It's use is illustrated below.\n",
        "* Note: *We don't need to initialise the parameters now.*"
      ]
    },
    {
      "metadata": {
        "id": "2Q3zOUybZwLa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class My_MNIST_Solver(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lin = nn.Linear(784, 10)\n",
        "  \n",
        "  def forward(self, xb):\n",
        "    return self.lin(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MCPDY7gra2vn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = My_MNIST_Solver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgAEg_wAbI_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "12a1bc1d-24c2-4d22-e0e1-2a79e14da939"
      },
      "cell_type": "code",
      "source": [
        "# pre-training\n",
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))\n",
        "fit(epochs=20)\n",
        "#post-training\n",
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2758, grad_fn=<NllLossBackward>) tensor(0.0469)\n",
            "tensor(0.2352, grad_fn=<NllLossBackward>) tensor(0.9219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U6Y9ubEse4WZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4th Refactor using optim\n",
        "* optim is the optimiser that we want to use.\n",
        "* Also helps in refactoring the training loop"
      ]
    },
    {
      "metadata": {
        "id": "WpR5SULxe8fP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_U-AsadQf_NO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model(lr=0.5):\n",
        "  model =  My_MNIST_Solver()\n",
        "  opt = optim.SGD(model.parameters(), lr=lr)\n",
        "  return model, opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-mf54kpcgeM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "05aed35c-2803-43ef-e12a-b3abe26879db"
      },
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//(bs+1)):\n",
        "    start = i * bs\n",
        "    end = start + bs\n",
        "    xb = x_train[start:end]\n",
        "    yb = y_train[start:end]\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "    opt.step() # Note: We just refactored p -= p.grad * lr and it's for loop\n",
        "    opt.zero_grad()\n",
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3810, grad_fn=<NllLossBackward>) tensor(0.0625)\n",
            "tensor(0.2679, grad_fn=<NllLossBackward>) tensor(0.9219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BYAz1xlChaEB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5th Refactor using Dataset\n",
        "* A Dataset can be anything that has a __ len __ function (called by Pythonâ€™s standard len function) and a __ getitem __ function as a way of indexing into it.\n",
        "* It allows us to easily slice along the first axis of the tensor (generally nth training example).\n",
        "* TensorDataset is a wrapper around the Dataset abstract class for tensor data."
      ]
    },
    {
      "metadata": {
        "id": "GWKBQNwGlfjA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7f5FKpEm3up",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fit(epochs=2, lr=0.5):\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n -1) // (bs + 1)):\n",
        "      xb, yb = train_ds[i*bs: i*bs + bs]\n",
        "      preds = model(xb)\n",
        "      loss = loss_func(preds, yb)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * lr\n",
        "        model.zero_grad() # Reset grads to zero for all parameter of the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MUU2bqoDnEv4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u-aHelxgwlSj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 6th Refactor using DataLoader\n",
        "* It helps in iterating through a dataset"
      ]
    },
    {
      "metadata": {
        "id": "JL4V5P66xAbQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4aVihDFxUSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "90e0fc50-8e8b-4c44-c5ab-1192c7e0d78f"
      },
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "print(loss_func(model(xb), yb))\n",
        "for epoch in range(epochs):\n",
        "  for xb, yb in train_dl:\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0714, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "alf4fk81yOJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea19abed-c58d-448c-ff2d-331e642d6a36"
      },
      "cell_type": "code",
      "source": [
        "print(accuracy(model(xb), yb))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZKgzst1QOnoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Adding Validation Set\n",
        "* Validation set doesn't require to store grads. So it takes lesser memory. Hence a larger batch size can be used."
      ]
    },
    {
      "metadata": {
        "id": "wfnPAwzzO2Y-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "\n",
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=2*bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsqsdWIEP9HH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ee80d91b-8713-45aa-ae92-c2c8af906df7"
      },
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for xb, yb in train_dl:\n",
        "    model.train() # Always written before training used by layers like BatchNorm and Dropout\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    model.eval() # Always written before evaluating used by layers like BatchNorm and Dropout\n",
        "    with torch.no_grad():\n",
        "      valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
        "  print(epoch, valid_loss)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(23.9505)\n",
            "1 tensor(25.9968)\n",
            "2 tensor(29.1557)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U5u5vRcQSIet",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Extreme Refactoring\n",
        "\n",
        "\n",
        "*   We will now write functions for calculating loss for a single batch.\n",
        "*   And like get_model() we will create another function called get_data() to get all the Dataloaders\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vBjjve1rSMXG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(train_ds, valid_ds, bs):\n",
        "  return (\n",
        "    DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "    DataLoader(valid_ds, batch_size=bs)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1BqWKK_vTGa0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "  preds = model(xb)\n",
        "  loss = loss_func(preds, yb)\n",
        "  \n",
        "  if opt is not None:\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  \n",
        "  return loss.item(), len(xb)\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UGjJWNjmU3sU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "\n",
        "        print(epoch, val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7hRRzEBBVNvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The following 3 lines can be used to train a wide variety of models."
      ]
    },
    {
      "metadata": {
        "id": "xRJYvtwcUvwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "65998503-cbb8-4e3b-ff47-e9bd8b92761f"
      },
      "cell_type": "code",
      "source": [
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
        "model, opt = get_model()\n",
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.3719518579483032\n",
            "1 0.30234507451057435\n",
            "2 0.3276525299549103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "229oCL_0Z4Xc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### CNN Implementation"
      ]
    },
    {
      "metadata": {
        "id": "_EGFj_PTZ62O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class My_MNIST_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = F.conv2d()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}